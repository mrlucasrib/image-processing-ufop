{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# -*- coding: utf-8 -*-\n", "\"\"\"Libras em V\u00eddeo.ipynb"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["Automatically generated by Colaboratory."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["Original file is located at\n", "    https://colab.research.google.com/drive/1A06mMyZlAx130ZWG9N00rZ0dHbfmAmps"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Projeto: Libras em v\u00eddeo"]}, {"cell_type": "markdown", "metadata": {}, "source": [" **Etapa 1 - Importando as bibliotecas**"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "import time<br>\n", "import sys<br>\n", "import cv2<br>\n", "import numpy as np<br>\n", "import matplotlib.pyplot as plt<br>\n", "import zipfile<br>\n", "from google.colab.patches import cv2_imshow<br>\n", "cv2.__version__<br>\n", "# **Etapa 2 - Conectando com o Drive**"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "from google.colab import drive<br>\n", "drive.mount('/content/drive')<br>\n", "pose_path = \"/content/drive/My Drive/pose.zip\"<br>\n", "zip_object = zipfile.ZipFile(file=pose_path, mode=\"r\")<br>\n", "zip_object.extractall(\"./\")<br>\n", "imagens_path = \"/content/drive/My Drive/imagens.zip\"<br>\n", "zip_object = zipfile.ZipFile(file=imagens_path, mode=\"r\")<br>\n", "zip_object.extractall(\"./\")<br>\n", "modulos_path = \"/content/drive/My Drive/modulos.zip\"<br>\n", "zip_object = zipfile.ZipFile(file=modulos_path, mode=\"r\")<br>\n", "zip_object.extractall(\"./\")<br>\n", "zip_object.close()<br>\n", "# Etapa 3 - Importando o m\u00f3dulo do Drive"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "sys.path.append('/content/modulos/')<br>\n", "sys.path<br>\n", "import extrator_POSICAO as posicao<br>\n", "import extrator_ALTURA as altura<br>\n", "import extrator_PROXIMIDADE as proximidade<br>\n", "import alfabeto<br>\n", "# **Etapa 4 - Carregando o modelo e estruturas da rede neural pr\u00e9-treinada**\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["arquivo_proto = \"/content/pose/hand/pose_deploy.prototxt\"\n", "arquivo_pesos = \"/content/pose/hand/pose_iter_102000.caffemodel\"\n", "numero_pontos = 22\n", "pares_pose = [[0, 1], [1, 2], [2, 3], [3, 4], [0, 5], [5, 6], [6, 7], [7, 8], \n", "              [0, 9], [9, 10], [10, 11], [11, 12], [0, 13], [13, 14], [14, 15], \n", "              [15, 16], [0, 17], [17, 18], [18, 19], [19, 20]]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["letras = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'I', 'L', 'M', 'N', 'O', 'P', \n", "          'Q', 'R', 'S', 'T', 'U', 'V', 'W']"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n## **Etapa 5 - Ler o modelo carregado na Etapa 3**<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["modelo = cv2.dnn.readNetFromCaffe(arquivo_proto, arquivo_pesos)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["cor_pontoA, cor_pontoB, cor_linha = (14, 201, 255), (255, 0, 128), (192, 192, 192)\n", "cor_txtponto, cor_txtinicial, cor_txtandamento = (10, 216, 245), (255, 0, 128), (54, 54, 54)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["tamanho_fonte, tamanho_linha, tamanho_circulo, espessura = 1, 1, 4, 2\n", "fonte = cv2.FONT_HERSHEY_SIMPLEX"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n## **Etapa 6 - Carregando um video do Drive**\n<br>\n", "video = \"/content/drive/My Drive/libras2.mp4\"<br>\n", "captura = cv2.VideoCapture(video)<br>\n", "ret, frame = captura.read()<br>\n", "ret<br>\n", "imagem_largura = frame.shape[1]<br>\n", "imagem_altura = frame.shape[0]<br>\n", "proporsao = imagem_largura / imagem_altura<br>\n", "imagem_largura, imagem_altura, proporsao<br>\n", "# **Etapa 7 - Definir as dimens\u00f5es da imagem de entrada.**"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "entrada_altura = 368<br>\n", "entrada_largura = int(((proporsao * entrada_altura) * 8) // 8)<br>\n", "entrada_largura, entrada_altura<br>\n", "# Etapa 7 - Criando a vari\u00e1vel para salvar os resultados no Drive"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "resultado = './libras.avi'<br>\n", "gravar_video = cv2.VideoWriter(resultado, cv2.VideoWriter_fourcc(*'XVID'), 10,<br>\n", "                              (frame.shape[1], frame.shape[0]))<br>\n", "# **Etapa 8 - Lendo o modelo carregado na Etapa 3**"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "modelo = cv2.dnn.readNetFromCaffe(arquivo_proto, arquivo_pesos)<br>\n", "# Etapa 9 - Exibindo as sa\u00eddas"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "limite = 0.1<br>\n", "while (cv2.waitKey(1) < 0):<br>\n", "    t = time.time()<br>\n", "    conectado, frame = captura.read()<br>\n", "    frame_copia = np.copy(frame)<br>\n", "    tamanho = cv2.resize(frame, (imagem_largura, imagem_altura))<br>\n", "    mapa_suave = cv2.GaussianBlur(tamanho, (3, 3), 0, 0)<br>\n", "    fundo = np.uint8(mapa_suave > limite)<br>\n", "    <br>\n", "    if not conectado:<br>\n", "        cv2.waitKey()<br>\n", "        break<br>\n", "    entrada_blob = cv2.dnn.blobFromImage(frame, 1.0 / 255, <br>\n", "                                         (entrada_largura, entrada_altura),<br>\n", "                                    (0, 0, 0), swapRB=False, crop=False)<br>\n", "    modelo.setInput(entrada_blob)<br>\n", "    saida = modelo.forward()<br>\n", "    pontos = []<br>\n", "    for i in range(numero_pontos):<br>\n", "        mapa_confianca = saida[0, i, :, :]<br>\n", "        mapa_confianca = cv2.resize(mapa_confianca, (imagem_largura, imagem_altura))<br>\n", "        <br>\n", "        _, confianca, _, point = cv2.minMaxLoc(mapa_confianca)<br>\n", "        if confianca > limite:<br>\n", "            cv2.circle(frame_copia, (int(point[0]), int(point[1])), <br>\n", "                       tamanho_circulo, cor_pontoA, thickness=espessura,<br>\n", "                       lineType=cv2.FILLED)<br>\n", "            cv2.putText(frame_copia, \"{}\".format(i), (int(point[0]), int(point[1])),<br>\n", "                        fonte, .8,<br>\n", "                        cor_txtponto, 2, lineType=cv2.LINE_AA)<br>\n", "            pontos.append((int(point[0]), int(point[1])))<br>\n", "        else:<br>\n", "            pontos.append((0, 0))<br>\n", "    for par in pares_pose:<br>\n", "        parteA = par[0]<br>\n", "        parteB = par[1]<br>\n", "        if pontos[parteA] != (0, 0) and pontos[parteB] != (0, 0):<br>\n", "            cv2.line(frame, pontos[parteA], pontos[parteB], cor_linha, <br>\n", "                     tamanho_linha, lineType=cv2.LINE_AA)<br>\n", "            cv2.circle(frame, pontos[parteA], tamanho_circulo, cor_pontoA,<br>\n", "                       thickness=espessura, lineType=cv2.FILLED)<br>\n", "            cv2.circle(frame, pontos[parteB], tamanho_circulo, cor_pontoB,<br>\n", "                       thickness=espessura, lineType=cv2.FILLED)<br>\n", "            cv2.line(fundo, pontos[parteA], pontos[parteB], cor_linha, <br>\n", "                     tamanho_linha, lineType=cv2.LINE_AA)<br>\n", "            cv2.circle(fundo, pontos[parteA], tamanho_circulo, cor_pontoA, <br>\n", "                       thickness=espessura, lineType=cv2.FILLED)<br>\n", "            cv2.circle(fundo, pontos[parteB], tamanho_circulo, cor_pontoB, <br>\n", "                       thickness=espessura, lineType=cv2.FILLED)<br>\n", "    posicao.posicoes = []<br>\n", "    # dedo polegar<br>\n", "    posicao.verificar_posicao_DEDOS(pontos[1:5], 'polegar', altura.verificar_altura_MAO(pontos))<br>\n", "    # dedo indicador<br>\n", "    posicao.verificar_posicao_DEDOS(pontos[5:9], 'indicador', altura.verificar_altura_MAO(pontos))<br>\n", "    # dedo m\u00e9dio<br>\n", "    posicao.verificar_posicao_DEDOS(pontos[9:13], 'medio', altura.verificar_altura_MAO(pontos))<br>\n", "    # dedo anelar<br>\n", "    posicao.verificar_posicao_DEDOS(pontos[13:17], 'anelar', altura.verificar_altura_MAO(pontos))<br>\n", "    # dedo m\u00ednimo<br>\n", "    posicao.verificar_posicao_DEDOS(pontos[17:21], 'minimo', altura.verificar_altura_MAO(pontos))<br>\n", "    for i, a in enumerate(alfabeto.letras):<br>\n", "        if proximidade.verificar_proximidade_DEDOS(pontos) == alfabeto.letras[i]:<br>\n", "            cv2.putText(frame, 'Letra: ' + letras[i], (50, 50), fonte, 1, <br>\n", "                        cor_txtinicial, tamanho_fonte,<br>\n", "                        lineType=cv2.LINE_AA)<br>\n", "        else:<br>\n", "            cv2.putText(frame, 'Analisando', (250, 50), fonte, 1, <br>\n", "                        cor_txtandamento, tamanho_fonte,<br>\n", "                        lineType=cv2.LINE_AA)<br>\n", "    <br>\n", "    cv2_imshow(frame)<br>\n", "    key = cv2.waitKey(1)<br>\n", "    if key == 27:<br>\n", "        break<br>\n", "    print(\"Tempo total = {:.2f}seg\".format(time.time() - t))<br>\n", "    gravar_video.write(frame)<br>\n", "gravar_video.release()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}